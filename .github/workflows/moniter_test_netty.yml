name: Moniter test Netty

on:
  workflow_dispatch:
jobs:
  setup:
    runs-on: ubuntu-latest
    strategy:
      max-parallel: 1
      fail-fast: false
      matrix:
        count: [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22]
        payload: [50]
        users: [1]
    timeout-minutes: 600
    env:
      TEST_NAME: "netty_hello"
      TEST_ROOT: "tests"
    steps:
    - name: CHECKOUT
      uses: actions/checkout@v2
    - name: AZURE LOGIN
      uses: azure/login@v1
      with:
        creds: ${{secrets.AZURE_CREDENTIALS}}
    - name: Create Cluster
      env:
        AZURE_APP_ID: ${{ secrets.AZURE_APP_ID }}
        AZURE_APP_PASSWORD: ${{ secrets.AZURE_APP_PASSWORD }}
        RESOURCE_GROUP: ${{ secrets.CLUSTER_RESOURCE_GROUP }}
        PPG_ID: "/subscriptions/${{ secrets.SUBSCRIPTION_ID }}/resourceGroups/ballerina-performance/providers/Microsoft.Compute/proximityPlacementGroups/${{ secrets.PPG_NAME }}"
      run: |
        az aks create \
            --resource-group "${RESOURCE_GROUP}" \
            --name bal-perf-med-${{ matrix.count }} \
            --service-principal "${AZURE_APP_ID}"\
            --client-secret "${AZURE_APP_PASSWORD}" \
            --node-vm-size "Standard_F16s_v2" \
            --node-osdisk-size 256 \
            --ppg "${PPG_ID}" \
            --node-osdisk-type Managed \
            --node-count 1 \
            --location "eastus" \
            --enable-addons monitoring \
            --workspace-resource-id ${{ secrets.LOG_WORKSPACE }} \
            --generate-ssh-keys
    - name: Configure AKS
      uses: azure/aks-set-context@v1
      with:
        creds: '${{ secrets.AZURE_CREDENTIALS }}'
        cluster-name: 'bal-perf-med-${{ matrix.count }}'
        resource-group: ${{ secrets.CLUSTER_RESOURCE_GROUP }}
    - name: Deploy Niginx
      run: |
        # Create a namespace for your ingress resources
        kubectl create namespace ingress-basic

        # Add the ingress-nginx repository
        helm repo add ingress-nginx https://kubernetes.github.io/ingress-nginx

        # Use Helm to deploy an NGINX ingress controller
        helm install nginx-ingress ingress-nginx/ingress-nginx \
            --namespace ingress-basic \
            --set controller.replicaCount=2 \
            --set controller.nodeSelector."beta\.kubernetes\.io/os"=linux \
            --set defaultBackend.nodeSelector."beta\.kubernetes\.io/os"=linux \
            --set controller.admissionWebhooks.patch.nodeSelector."beta\.kubernetes\.io/os"=linux
        # Wait for ingress ip
        kubectl get service nginx-ingress-ingress-nginx-controller --namespace ingress-basic -w  \
        -o 'go-template={{with .status.loadBalancer.ingress}}{{range .}}{{.ip}}{{"\n"}}{{end}}{{.err}}{{end}}' 2>/dev/null \
        | head -n1
    - name: Login to DockerHub
      uses: docker/login-action@v1
      with:
        username: ${{ secrets.DOCKER_HUB_USERNAME }}
        password: ${{ secrets.DOCKER_HUB_ACCESS_TOKEN }}
    - name: Configure AKS
      uses: azure/aks-set-context@v1
      with:
        creds: '${{ secrets.AZURE_CREDENTIALS }}'
        cluster-name: 'bal-perf-med-${{ matrix.count }}'
        resource-group: ${{ secrets.CLUSTER_RESOURCE_GROUP }}
    - name: Deploy artifacts
      run: |
        kubectl apply -f ${TEST_ROOT}/${TEST_NAME}/k8s.yaml
    - name: Login via Az module
      uses: azure/login@v1
      with:
        creds: ${{secrets.AZURE_CREDENTIALS}}
    - name: Write values to outputs
      id: write
      run: |
        echo "::set-output name=cluster-ip::$(kubectl get service nginx-ingress-ingress-nginx-controller --namespace ingress-basic -w  \
                                              -o 'go-template={{with .status.loadBalancer.ingress}}{{range .}}{{.ip}}{{"\n"}}{{end}}{{.err}}{{end}}' 2>/dev/null \
                                              | head -n1)"
        echo "::set-output name=scenario-name::${TEST_NAME}"
        echo "::set-output name=vm-name::bal-perf-vm-`echo ${TEST_NAME} | tr '_' '-'`-${{ matrix.users }}-${{ matrix.payload }}-${{ GITHUB.RUN_NUMBER }}"
        echo "::set-output name=custom-image-name::$(cat image.txt)"
        echo "::set-output name=ppg-id::/subscriptions/${{ secrets.SUBSCRIPTION_ID }}/resourceGroups/ballerina-performance/providers/Microsoft.Compute/proximityPlacementGroups/${{ secrets.PPG_NAME }}"
    - name: Create VM Instance
      id: vminstance
      uses: azure/CLI@v1
      with:
        azcliversion: "agentazcliversion"
        inlineScript: |
          az vm create --resource-group "${{ secrets.CLUSTER_RESOURCE_GROUP }}"  --name "${{ steps.write.outputs.vm-name }}"  --admin-username "${{ secrets.VM_USER }}" --admin-password "${{ secrets.VM_PWD }}" --location  eastus \
          --image "Canonical:UbuntuServer:18.04-LTS:latest" --tags benchmark-number=${{ steps.write.outputs.vm-name }} --size Standard_F4s_v2 --ppg ${{ steps.write.outputs.ppg-id }}
          echo "::set-output name=ip-address::$(az vm show -d -g "${{ secrets.CLUSTER_RESOURCE_GROUP }}" -n "${{ steps.write.outputs.vm-name }}" --query publicIps -o tsv)"
    - name: Execute performance tests
      uses: appleboy/ssh-action@master
      env: 
        IP: ${{ steps.write.outputs.cluster-ip }}
        SCENARIO_NAME: ${{ steps.write.outputs.scenario-name }}
        PAYLOAD: ${{ matrix.payload }}
        USERS: ${{ matrix.users }}
      with:
        host: ${{ steps.vminstance.outputs.ip-address }}
        username: ${{ secrets.VM_USER }}
        password: ${{ secrets.VM_PWD }}
        envs: IP,SCENARIO_NAME,PAYLOAD,USERS
        command_timeout: '180m' #3 hours
        timeout: 300s #5 mins
        script: |
          git clone https://github.com/xlight05/ballerina-performance-cloud
          sudo cp -r ballerina-performance-cloud/base-image /
          sudo chmod -R 777 /base-image
          sh /base-image/init.sh
          source /etc/profile.d/10-perf-vm.sh
          execute-tests.sh -c $IP -s $SCENARIO_NAME -p $PAYLOAD -u $USERS
    - name: Undeploy artifacts
      run: |
        kubectl delete -f ${TEST_ROOT}/${TEST_NAME}/k8s.yaml
    - name: Cleanup VM
      if: always()
      continue-on-error: true
      uses: azure/CLI@v1
      with:
        azcliversion: "agentazcliversion"
        inlineScript: |
          az resource delete --ids $(az resource list --tag benchmark-number=${{ steps.write.outputs.vm-name }} -otable --query "[].id" -otsv)
          var=`az disk list --query "[?tags.\"benchmark-number\"=='${{ steps.write.outputs.vm-name }}'].id" -otable -otsv`
          if [ -n "$var" ]
          then
              az resource delete --ids ${var}
          else
              echo "Disk is already deleted"
          fi
    - name: Cleaning up the cluster
      if: always()
      uses: azure/CLI@v1
      with:
        azcliversion: "agentazcliversion"
        inlineScript: |
          az group delete --name mc_${{ secrets.CLUSTER_RESOURCE_GROUP }}_bal-perf-med-${{ matrix.count }}_eastus -y
          az aks delete --name bal-perf-med-${{ matrix.count }} --resource-group ${{ secrets.CLUSTER_RESOURCE_GROUP }} -y